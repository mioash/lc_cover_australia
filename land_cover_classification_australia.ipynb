{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## \n",
    "## Supplemental information produced to: \n",
    "## “High-resolution time-series land-cover mapping and land change assessment for Australia from 1985 to 2015” \n", 
    "## This paper has been submitted for publication in Remote Sensing of Environment. \n",
    "## Authors: Marco Calderón-Loor 1,2 *, Michalis Hadjikakou 1, Brett A Bryan 1 \n",
    "## 1 Centre for Integrative Ecology, Deakin University, Melbourne, Australia \n",
    "## 2 Grupo de Investigación de Biodiversidad, Medio Ambiente y Salud–BIOMAS, Universidad de las Américas (UDLA), Quito, Ecuador \n",
    "## * Email: mcalderonloor@deakin.edu.au, mioash@gmail.com \n"

    "##Import and Initialize Google Earth Engine \n",
    "import ee  \n",
    "from ee import batch\n",
    "\n",
    "# Initialize the Earth Engine object, using the authentication credentials.\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading required assets\n",
    "# Australia's shapefile\n",
    "area_shape = ee.FeatureCollection('users/mioash/aust_cd66states')\n",
    "\n",
    "# Training and Validation datasets\n",
    "fc = ee.FeatureCollection('users/mioash/Calderon_etal_Australian_land-cover/train_6c_lcaus')\n",
    "fct = ee.FeatureCollection('users/mioash/Calderon_etal_Australian_land-cover/test_6c_lcaus')\n",
    "\n",
    "# Load Landsat 5, 7 & 8\n",
    "l5 = ee.ImageCollection('LANDSAT/LT05/C01/T1_SR')\n",
    "l7 = ee.ImageCollection('LANDSAT/LE07/C01/T1_SR')\n",
    "l8 = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
    "\n",
    "# Load extra datasets\n",
    "ligths = ee.ImageCollection('NOAA/DMSP-OLS/NIGHTTIME_LIGHTS')\n",
    "ecoregions = ee.FeatureCollection('users/mioash/tnc_aus_ecoregions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for data pre-processing and spectral index calculation\n",
    "\n",
    "#months to take into account\n",
    "mini = 1\n",
    "mfin = 12\n",
    "\n",
    "## Fmask algorithm\n",
    "def maskClouds(image):\n",
    " #// bit positions: find by raising 2 to the bit flag code \n",
    " cloudBit = 2**5 #//32\n",
    " shadowBit = 2**3 #// 8\n",
    " snowBit = 2**4 #//16\n",
    " fillBit = 2**0 #// 1\n",
    " #// extract pixel quality band\n",
    " qa = image.select('pixel_qa')    \n",
    " #// create and apply mask\n",
    " mask = qa.bitwiseAnd(cloudBit).eq(0).And(  #// no clouds\n",
    "             qa.bitwiseAnd(shadowBit).eq(0)).And( #// no cloud shadows\n",
    "             qa.bitwiseAnd(snowBit).eq(0)).And(   #// no snow\n",
    "             qa.bitwiseAnd(fillBit).eq(0))    #// no fill\n",
    " return image.updateMask(mask)\n",
    "\n",
    "# Calculate and add spectral indices to every image\n",
    "def add_predictors(img):\n",
    "  #img = img.select(['B1','B2','B3','B4','B5','B7'])\n",
    "  ndvi = img.normalizedDifference(['B4', 'B3']).rename('NDVI')\n",
    "  ndwi = img.normalizedDifference(['B2', 'B4']).rename(['NDWI'])\n",
    "  ndbi = img.normalizedDifference(['B5', 'B4']).rename(['NDBI'])\n",
    "  wbi = img.select('B1').divide(img.select('B4')).rename(['WBI'])\n",
    "  evi = img.expression(\n",
    "    '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n",
    "      'NIR': img.select('B4'),\n",
    "      'RED': img.select('B3'),\n",
    "      'BLUE': img.select('B1')\n",
    "}).rename(['EVI'])\n",
    "  msavi2 = img.expression(\n",
    "    '1/2 * ((2*NIR+1) - ((2*NIR+1)**2 - 8*(NIR-RED))**(1/2))',{\n",
    "      'NIR': img.select('B4'),\n",
    "      'RED': img.select('B3')\n",
    "  }).rename(['MSAVI2'])\n",
    "  savi = img.expression(\n",
    "    '((NIR-RED) / (RED+NIR+0.5))*(1.5)', {\n",
    "      'RED': img.select('B3'),\n",
    "      'NIR': img.select('B4')\n",
    "  }).rename(['SAVI'])\n",
    "  osavi = img.expression(\n",
    "    '((NIR-RED) / (RED+NIR+0.16))', {\n",
    "      'RED': img.select('B3'),\n",
    "      'NIR': img.select('B4')\n",
    "  }).rename(['OSAVI'])\n",
    "  satvi = img.expression(\n",
    "    '(((SWIR1-RED) / (SWIR1+RED+0.5))*1.5) - (SWIR2/2)',{\n",
    "      'SWIR1': img.select('B5'),\n",
    "      'RED': img.select('B3'),\n",
    "      'SWIR2': img.select('B7')\n",
    "    }).rename(['SATVI'])\n",
    "  bsi = img.expression( #updated\n",
    "    '((SWIR2+RED)-(NIR+BLUE))/((SWIR2+RED)+(NIR+BLUE))',{\n",
    "      'SWIR2': img.select('B7'),\n",
    "      'NIR': img.select('B4'),\n",
    "      'RED': img.select('B3'),\n",
    "      'BLUE':img.select('B1')\n",
    "  }).rename(['BSI'])\n",
    "  br = img.select('B1').subtract(img.select('B3')).rename(['BR'])\n",
    "  bg = img.normalizedDifference(['B1', 'B2']).rename(['BG'])\n",
    "  indexMax = ndvi.max(ndwi).rename('indexMax')\n",
    "  return img.addBands([ndvi.float(),ndwi.float(),ndbi.float(),wbi.float(),evi.float(),msavi2.float(),savi.float(),\n",
    "                       osavi.float(),satvi.float(),bsi.float(),br.float(),bg.float(),indexMax.float()])\n",
    "\n",
    "def filtro (im,y1,y2):\n",
    "  filt = im.filter(ee.Filter.calendarRange(ee.Number(y1),ee.Number(y2),'year')).filter(ee.Filter.calendarRange(ee.Number(1),ee.Number(12),'month'))\n",
    "  return filt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply functions to L5 and L7 ImageCollection\n",
    "l5 = l5.filterDate(ee.Date.fromYMD(1984,1,1), ee.Date.fromYMD(2012,12,31)).filterBounds(area_shape).map(maskClouds).select(['B1','B2','B3','B4','B5','B7']).map(add_predictors)\n",
    "l7 = l7.filterDate(ee.Date.fromYMD(1999,1,1), ee.Date.fromYMD(2015,12,31)).filterBounds(area_shape).map(maskClouds).select(['B1','B2','B3','B4','B5','B7']).map(add_predictors)\n",
    "l8 = l8.filterDate(ee.Date.fromYMD(2013,1,1), ee.Date.fromYMD(2017,12,31)).filterBounds(area_shape).map(maskClouds)\n",
    "def rrename(imgc):\n",
    "    return imgc.select(['B2','B3','B4','B5','B6','B7']).rename(['B1','B2','B3','B4','B5','B7'])\n",
    "l8 = l8.map(rrename).map(add_predictors)\n",
    "\n",
    "l5_85 = filtro(l5,1984,1988).median()\n",
    "l5_90 = filtro(l5,1988,1992).median()\n",
    "l5_95 = filtro(l5,1993,1997).median()\n",
    "l5_00 = filtro(l5,1998,2002).median()\n",
    "l5_05 = filtro(l5,2003,2007).median()\n",
    "l5_10 = filtro(l5,2008,2012).median()\n",
    "l7_00 = filtro(l7,1999,2002).median()\n",
    "l7_05 = filtro(l7,2003,2007).median()\n",
    "l7_10 = filtro(l7,2008,2012).median()\n",
    "l7_15 = filtro(l7,2013,2015).median()\n",
    "l8_15 = filtro(l8,2013,2017).median()\n",
    "\n",
    "def unir (im1,im2):\n",
    "    unn = ee.ImageCollection([ee.Image(im1), ee.Image(im2)])\n",
    "    unn = unn.reduce(ee.Reducer.mean()).select(\n",
    "        ['B1_mean','B2_mean', 'B3_mean', 'B4_mean','B5_mean','B7_mean' ,'NDVI_mean','NDWI_mean','NDBI_mean','WBI_mean','EVI_mean',\n",
    "         'MSAVI2_mean','SAVI_mean','OSAVI_mean','SATVI_mean','BSI_mean',\n",
    "         'BR_mean','BG_mean','indexMax_mean'], #// old names\n",
    "        ['B1','B2','B3','B4','B5','B7','NDVI','NDWI','NDBI','WBI','EVI',\n",
    "         'MSAVI2','SAVI','OSAVI','SATVI','BSI','BR','BG','indexMax'])#// new names\n",
    "    return unn\n",
    "\n",
    "l57_00 = unir(l5_00,l7_00)\n",
    "l57_05 = unir(l5_05,l7_05)\n",
    "l57_10 = unir(l5_10,l7_10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro1 (im,y1,y2,mini,mfin,old_bands, season):\n",
    "    filt1= im.filter(ee.Filter.calendarRange(ee.Number(y1),ee.Number(y2),'year')).filter(ee.Filter.calendarRange(ee.Number(mini),ee.Number(mfin),'month'))\n",
    "    new_bands = [x + season for x in oldbands]\n",
    "    filt1 = filt1.median().select(old_bands,new_bands)\n",
    "    return filt1\n",
    "\n",
    "oldbands = ['B1','B2', 'B3', 'B4','B5','B7' ,'NDVI','NDWI','NDBI','WBI','EVI',\n",
    "         'MSAVI2','SAVI','OSAVI','SATVI','BSI','BR','BG']\n",
    "def add_seasons (img,y_ini,y_end):\n",
    "    djf = filtro1(img,y_ini,y_end,12,2,oldbands,'_DJF')\n",
    "    mam = filtro1(img,y_ini,y_end,3,5,oldbands,'_MAM')\n",
    "    jja = filtro1(img,y_ini,y_end,6,8,oldbands,'_JJA')\n",
    "    son = filtro1(img,y_ini,y_end,9,11,oldbands,'_SON')\n",
    "    fs = filtro1(img,y_ini,y_end,1,6,oldbands,'_FS')\n",
    "    ss = filtro1(img,y_ini,y_end,7,12,oldbands,'_SS')\n",
    "    return djf.addBands(mam).addBands(jja).addBands(son).addBands(fs).addBands(ss)\n",
    "\n",
    "l5_85a = l5_85.addBands(add_seasons(l5,1984,1988))\n",
    "l5_90a = l5_90.addBands(add_seasons(l5,1988,1992))\n",
    "l5_95a = l5_95.addBands(add_seasons(l5,1993,1997))\n",
    "l5_00a = l5_00.addBands(add_seasons(l5,1998,2002))\n",
    "l5_05a = l5_05.addBands(add_seasons(l5,2003,2007))\n",
    "l5_10a = l5_10.addBands(add_seasons(l5,2008,2012))\n",
    "l7_00a = l7_00.addBands(add_seasons(l7,1999,2002))\n",
    "l7_05a = l7_05.addBands(add_seasons(l7,2003,2007))\n",
    "l7_10a = l7_10.addBands(add_seasons(l7,2008,2012))\n",
    "l8_15a = l8_15.addBands(add_seasons(l8,2013,2017))\n",
    "l57_00a = l5_00a.add(l7_00a)\n",
    "l57_00a = l57_00a.divide(2)\n",
    "\n",
    "l57_05a = l5_05a.add(l7_05a)\n",
    "l57_05a = l57_05a.divide(2)\n",
    "\n",
    "l57_10a = l5_10a.add(l7_10a)\n",
    "l57_10a = l57_10a.divide(2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding biophysical information\n",
    "\n",
    "def filtrolt (im):\n",
    "  #filtlt= im.filterDate(ee.Date.fromYMD(1992,1,1), ee.Date.fromYMD(1995,12,31)).min().float().clip(area_shape)\n",
    "  return im.filter(ee.Filter.calendarRange(1992,2000,'year')).filter(ee.Filter.calendarRange(1,12,'month')).min().float().clip(area_shape)\n",
    "    \n",
    "# Resample night-ligths\n",
    "n1992 = filtrolt(ligths)#.ad\n",
    "n1992a = n1992.select('stable_lights').unitScale(0,63).resample('bilinear')#.divide(63).resample('bilinear')\n",
    "n1992a = n1992.select('stable_lights')\n",
    "\n",
    "# Load, fill and add -bioclimatic variables, elevation and slope\n",
    "proj = l5_85a.projection()\n",
    "bioclim = ee.Image('WORLDCLIM/V1/BIO').select(['bio01','bio12'],['Mean_Temp', 'Prec']).clip(area_shape)\n",
    "def fill_holes (img,n_iter,min_scale,max_scale,increment):\n",
    "    vals1 = ee.List.sequence(min_scale,max_scale,increment)\n",
    "    for i in range(0,n_iter):\n",
    "        val = vals1.get(ee.Number(i))\n",
    "        imm1 = img.reproject(proj.atScale(val))\n",
    "        img = img.unmask(imm1,False)        \n",
    "    return img.clip(area_shape)\n",
    "bioclim = fill_holes(bioclim,7,2000,10000,1000)\n",
    "\n",
    "#//Elevation\n",
    "elevation = ee.Image('USGS/SRTMGL1_003').rename(['Elevation']).clip(area_shape)\n",
    "slope = ee.Terrain.slope(elevation).rename(['Slope'])\n",
    "eco_mask = ee.Image().float().paint(ecoregions, 'WWF_MHTNUM').rename('ecoregion').clip(area_shape)\n",
    "\n",
    "l5_85a = l5_85a.addBands(n1992a).addBands(eco_mask)\n",
    "l5_85a = l5_85a.addBands(l5_85a.normalizedDifference(['stable_lights', 'NDVI']).rename(['mndui'])).addBands(bioclim).addBands(elevation).addBands(slope)\n",
    "l5_90a = l5_90a.addBands(n1992a).addBands(eco_mask)\n",
    "l5_90a = l5_90a.addBands(l5_90a.normalizedDifference(['stable_lights', 'NDVI']).rename(['mndui'])).addBands(bioclim).addBands(elevation).addBands(slope)\n",
    "l5_95a = l5_95a.addBands(n1992a).addBands(eco_mask)\n",
    "l5_95a = l5_95a.addBands(l5_95a.normalizedDifference(['stable_lights', 'NDVI']).rename(['mndui'])).addBands(bioclim).addBands(elevation).addBands(slope)\n",
    "l57_00a = l57_00a.addBands(n1992a).addBands(eco_mask)\n",
    "l57_00a = l57_00a.addBands(l57_00a.normalizedDifference(['stable_lights', 'NDVI']).rename(['mndui'])).addBands(bioclim).addBands(elevation).addBands(slope)\n",
    "l57_05a = l57_05a.addBands(n1992a).addBands(eco_mask)\n",
    "l57_05a = l57_05a.addBands(l57_05a.normalizedDifference(['stable_lights', 'NDVI']).rename(['mndui'])).addBands(bioclim).addBands(elevation).addBands(slope)\n",
    "l57_10a = l57_10a.addBands(n1992a).addBands(eco_mask)\n",
    "l57_10a = l57_10a.addBands(l57_10a.normalizedDifference(['stable_lights', 'NDVI']).rename(['mndui'])).addBands(bioclim).addBands(elevation).addBands(slope)\n",
    "l8_15a = l8_15a.addBands(n1992a).addBands(eco_mask)\n",
    "l8_15a = l8_15a.addBands(l8_15a.normalizedDifference(['stable_lights', 'NDVI']).rename(['mndui'])).addBands(bioclim).addBands(elevation).addBands(slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands= ['SATVI_JJA', 'BSI_SON', 'BR_FS', 'B5_SS', 'B5_DJF', 'MSAVI2_SS','EVI_DJF','EVI_SON', \n",
    "    'BR_JJA', 'NDWI_JJA', 'NDBI_SON', 'B7_SS', 'BR_DJF', 'B4', 'BG_DJF', 'MSAVI2_FS', \n",
    "    'B2_SS', 'NDWI', 'WBI', 'Prec', 'WBI_JJA', 'OSAVI_DJF', 'SAVI', 'B1_MAM','B2_MAM', \n",
    "    'NDWI_FS', 'MSAVI2_SON', 'BR_MAM', 'NDBI_DJF', 'NDVI_DJF', 'NDBI_JJA', 'NDVI_SON',\n",
    "    'BG_SS', 'B3', 'mndui', 'Mean_Temp', 'NDBI_MAM', 'BSI', 'EVI','B1_FS', 'BR_SON', 'Slope', \n",
    "    'B3_FS', 'Elevation', 'EVI_JJA', 'B2', 'B4_DJF','ecoregion']\n",
    "\n",
    "rp = ee.FeatureCollection(fc)\n",
    "rpt = ee.FeatureCollection(fct)\n",
    "\n",
    "# Change the base-year image\n",
    "imtrain = l57_05a.select(bands)\n",
    "name_t = 'smile_aus_l5705_0604'\n",
    "\n",
    "rpp= imtrain.reproject('EPSG: 3665')\n",
    "\n",
    "trainingPartition = rpp.sampleRegions(rp,['Class'],tileScale=8)\n",
    "num_arbol = 100\n",
    "\n",
    "testingPartition = rpp.sampleRegions(rpt,['Class'],tileScale=8)\n",
    "\n",
    "# Temporal variables for creating k-folds\n",
    "t_C0 = trainingPartition.filterMetadata('Class','equals',ee.Number(0))\n",
    "t_C1 = trainingPartition.filterMetadata('Class','equals',ee.Number(1))\n",
    "t_C2 = trainingPartition.filterMetadata('Class','equals',ee.Number(2))\n",
    "t_C3 = trainingPartition.filterMetadata('Class','equals',ee.Number(3))\n",
    "t_C4 = trainingPartition.filterMetadata('Class','equals',ee.Number(4))\n",
    "t_C5 = trainingPartition.filterMetadata('Class','equals',ee.Number(5))\n",
    "\n",
    "def seedo(nnn):\n",
    "    #get random columns for each land-cover type\n",
    "    random0 = t_C0.randomColumn('random', nnn);\n",
    "    random1 = t_C1.randomColumn('random', nnn);\n",
    "    random2 = t_C2.randomColumn('random', nnn);\n",
    "    random3 = t_C3.randomColumn('random', nnn);\n",
    "    random4 = t_C4.randomColumn('random', nnn);\n",
    "    random5 = t_C5.randomColumn('random', nnn);\n",
    "    subsample = random0.filter(ee.Filter.lt('random', 0.8)).merge(\n",
    "        random1.filter(ee.Filter.lt('random', 0.8))).merge(\n",
    "        random2.filter(ee.Filter.lt('random', 0.8))).merge(\n",
    "        random3.filter(ee.Filter.lt('random', 0.8))).merge(\n",
    "        random4.filter(ee.Filter.lt('random', 0.8))).merge(\n",
    "        random5.filter(ee.Filter.lt('random', 0.8))) \n",
    "    trainedClassifier = ee.Classifier.smileRandomForest(num_arbol).train(subsample, 'Class',bands)\n",
    "    im_trained = imtrain.classify(trainedClassifier)\n",
    "    return im_trained\n",
    "\n",
    "c = ee.ImageCollection(ee.List.sequence(1,10).map(seedo))\n",
    "d = c.toBands().regexpRename('^(.*)', 'b_$1')\n",
    "modee = c.reduce(ee.Reducer.mode())\n",
    "\n",
    "\n",
    "# Calculate entropy\n",
    "total = c.reduce('count')\n",
    "\n",
    "# Class and counts\n",
    "fr = c.reduce(ee.Reducer.autoHistogram(6, 1))\n",
    "\n",
    "# Just get the counts\n",
    "p = fr.arraySlice(1, 1).divide(total)\n",
    "\n",
    "# mask array\n",
    "ct=p.neq(0)\n",
    "p = p.arrayMask(ct)\n",
    "\n",
    "# Log with custom base\n",
    "def log_b(x,base):\n",
    "    return x.log().divide(ee.Number(base).log())\n",
    "# Entropy\n",
    "H = log_b(p, 2).multiply(p).arrayReduce('sum', [0]).arrayFlatten([['ent'], ['']]).multiply(-1)\n",
    "\n",
    "# Export image\n",
    "llx = 108.76 \n",
    "lly = -44 \n",
    "urx = 155 \n",
    "ury = -10  #australia\n",
    "geometry = [[llx,lly], [llx,ury], [urx,ury], [urx,lly]]\n",
    "\n",
    "img_exp=d\n",
    "\n"
    
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
